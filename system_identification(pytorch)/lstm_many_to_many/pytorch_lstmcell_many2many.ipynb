{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def training_data_describe(training_set_path):\n",
    "    training_set=pd.read_csv(training_set_path)\n",
    "    training_data_describe=pd.DataFrame()\n",
    "    training_data_describe[\"std\"]=round(training_set.std(),3)\n",
    "    training_data_describe[\"mean\"]=round(training_set.mean(),3)\n",
    "    training_data_describe[\"max\"]=round(training_set.max(),3)\n",
    "    training_data_describe[\"min\"]=round(training_set.min(),3)\n",
    "    training_data_describe=training_data_describe.T\n",
    "    training_data_describe.index.name=\"describe\"\n",
    "    training_data_describe.to_csv(\"data_describ_2y.csv\")\n",
    "    return training_data_describe\n",
    "\n",
    "def data_norm(df):\n",
    "    df_norm=df\n",
    "    for i in df.columns:\n",
    "        df_norm[i]=(df_norm[i]-training_data_describe.loc['mean',i])/training_data_describe.loc['std',i]\n",
    "    return df_norm\n",
    "\n",
    "def buildWindows(data, windowsize=10,feature=5):\n",
    "    X_Window, Y_Window = [], []\n",
    "    for i in range(data.shape[0]-windowsize+1):\n",
    "        data_select=data.iloc[i:i+windowsize,0:feature:].drop_duplicates()\n",
    "        if data_select.shape[0]==data.iloc[i:i+windowsize,0:feature:].shape[0]:\n",
    "            Y_Window.append(np.array(data.iloc[i+past:i+windowsize,feature:]))\n",
    "            X_Window.append(np.array(data.iloc[i:i+windowsize,0:feature])) \n",
    "    return np.array(X_Window), np.array(Y_Window)\n",
    "\n",
    "def window_p(training_set_norm,mode):\n",
    "    X_train_W, Y_train_W = buildWindows(training_set_norm, WindowsSize,featureNum)\n",
    "    if mode==\"Train\":\n",
    "        X_train, Y_train, X_val, Y_val = splitData(X_train_W, Y_train_W, 0.8)\n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "    if mode==\"Test\":\n",
    "        return X_train_W, Y_train_W\n",
    "\n",
    "def splitData(X,Y,val_size,mode):\n",
    "    if mode==\"random\":\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=val_size, random_state=42)\n",
    "    if mode==\"normal\":\n",
    "        X_train = X[:int(X.shape[0]*(1-val_size))]\n",
    "        Y_train = Y[:int(Y.shape[0]*(1-val_size))]\n",
    "        X_val = X[int(X.shape[0]*(1-val_size)):]\n",
    "        Y_val = Y[int(Y.shape[0]*(1-val_size)):]\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def data_plot(rawdata):\n",
    "    plt.style.use('ggplot')\n",
    "    column_name=rawdata.columns\n",
    "    column_num=len(column_name)\n",
    "    column_p=[]\n",
    "    plt.figure(figsize=(50,column_num*10)).patch.set_facecolor('white')\n",
    "    data_P=rawdata\n",
    "    for idx, i in enumerate(column_name):\n",
    "        plt.subplot(column_num,1,idx+1)\n",
    "        plt.title(i,fontsize=50)\n",
    "        plt.scatter(rawdata.index,rawdata[i],s=5,c=\"#56B4E9\")\n",
    "        plt.yticks(fontsize=40)\n",
    "        plt.xticks(fontsize=40,rotation=45)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare torch data\n",
    "class PrepareData(Data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        if not torch.is_tensor(X):\n",
    "            self.X = torch.from_numpy(X)\n",
    "        if not torch.is_tensor(y):\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class softsensor(nn.Module):\n",
    "    def __init__(self,input_feature_dim,hidden_feature_dim1,hidden_feature_dim2,classes_num,gpu):\n",
    "        super(softsensor, self).__init__()\n",
    "        \n",
    "        self.input_feature_dim=input_feature_dim\n",
    "        self.hidden_feature_dim1=hidden_feature_dim1\n",
    "        self.hidden_feature_dim2=hidden_feature_dim2\n",
    "        \n",
    "        #Initialization        \n",
    "        self.lstm1=nn.LSTMCell(input_feature_dim,hidden_feature_dim1,bias=False)   \n",
    "        self.lstm2=nn.LSTMCell(hidden_feature_dim1,hidden_feature_dim2,bias=False) \n",
    "        self.linear1=nn.Linear(hidden_feature_dim2,classes_num,bias=False)\n",
    "        \n",
    "    def init_hidden(self,batch_size,gpu):\n",
    "        if gpu==True:\n",
    "            h01=torch.zeros(batch_size,self.hidden_feature_dim1).cuda()\n",
    "            c01=torch.zeros(batch_size,self.hidden_feature_dim1).cuda()\n",
    "            h02=torch.zeros(batch_size,self.hidden_feature_dim2).cuda()\n",
    "            c02=torch.zeros(batch_size,self.hidden_feature_dim2).cuda()\n",
    "        else:\n",
    "            h01=torch.zeros(batch_size,self.hidden_feature_dim1)\n",
    "            c01=torch.zeros(batch_size,self.hidden_feature_dim1)\n",
    "            h02=torch.zeros(batch_size,self.hidden_feature_dim2)\n",
    "            c02=torch.zeros(batch_size,self.hidden_feature_dim2)\n",
    "        \n",
    "        return (h01,c01,h02,c02)\n",
    "  \n",
    "    def forward(self,input,batchsize,gpu):\n",
    "        h01,c01,h02,c02=self.init_hidden(batchsize,gpu)\n",
    "        h1=h01\n",
    "        c1=c01\n",
    "        h2=h02\n",
    "        c2=c02\n",
    "        output = []\n",
    "        for i in range(input.size()[1]):\n",
    "            xt=input[:,i,:]\n",
    "            h1,c1=self.lstm1(xt.float(),(h01,c01))\n",
    "            h1=F.tanh(h1)\n",
    "            #output=F.dropout(output, p=0.1,training=self.training)\n",
    "            h2,c2=self.lstm2(h1,(h2,c2))\n",
    "            h2=F.tanh(h2)\n",
    "            #output=F.dropout(output, p=0.1,training=self.training)\n",
    "            output.append(h2)\n",
    "        output=torch.stack(output)\n",
    "        output=output.permute(1, 0, 2)\n",
    "        linear_output=self.linear1(output[:,past:])\n",
    "        return linear_output\n",
    "    \n",
    "    def mpc_test(self,input,batchsize,gpu):\n",
    "            h01,c01,h02,c02=self.init_hidden(batchsize,gpu)\n",
    "            h1=h01\n",
    "            c1=c01\n",
    "            h2=h02\n",
    "            c2=c02\n",
    "            outputs = []\n",
    "            y=[]\n",
    "            for i in range(input.size()[1]):\n",
    "                if i<=(past-1):\n",
    "                    xt=input[:,i,:]      \n",
    "                    h1,c1=self.lstm1(xt.float(),(h01,c01))\n",
    "                    #h1=self.BN1(h1)\n",
    "                    h1=F.tanh(h1)\n",
    "                    h2,c2=self.lstm2(h1,(h2,c2))\n",
    "                    #h2=self.BN2(h2)\n",
    "                    h2=F.tanh(h2)\n",
    "                    output=self.linear1(h2)\n",
    "                    outputs.append(output)\n",
    "                    y=output\n",
    "                if i>(past-1):\n",
    "                    xt=input[:,i,:]\n",
    "\n",
    "                    xt[0,3]=y[0][0]\n",
    "                    xt[0,4]=y[0][1]\n",
    "                    h1,c1=self.lstm1(xt.float(),(h01,c01))\n",
    "                    #h1=self.BN1(h1)\n",
    "                    h1=F.tanh(h1)\n",
    "                    h2,c2=self.lstm2(h1,(h2,c2))\n",
    "                    #h2=self.BN2(h2)\n",
    "                    h2=F.tanh(h2)\n",
    "                    output=self.linear1(h2)\n",
    "                    outputs.append(output)\n",
    "                    y=output\n",
    "\n",
    "            outputs=torch.stack(outputs)\n",
    "            return outputs[past:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "from pytorchtools import EarlyStopping\n",
    "#Train the Model using Early Stopping\n",
    "def train_model(model, batch_size, patience, n_epochs,gpu):\n",
    "    if gpu==True:\n",
    "        model.to('cuda:0')\n",
    "        \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    " \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        print(\"training\")\n",
    "        for batch, (data, target) in enumerate(train_loader, 1):\n",
    "            \n",
    "            if gpu==True:\n",
    "                data=data.cuda()\n",
    "                target=target.cuda()\n",
    "            else:\n",
    "                data=data\n",
    "                target=target\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.float().cuda(), batch_size,gpu=True)\n",
    "            # calculate the loss\n",
    "            trainloss = criterion(output.double(), target.double())\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            trainloss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(trainloss.item())\n",
    " \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        print(\"validation\")\n",
    "        for data, target in valid_loader:\n",
    "            \n",
    "            if gpu==True:\n",
    "                data=data.cuda()\n",
    "                target=target.cuda()\n",
    "            else:\n",
    "                data=data\n",
    "                target=target\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.float(), batch_size,gpu=True)\n",
    "            # calculate the loss\n",
    "            valloss = criterion(output.double(), target.double())\n",
    "\n",
    "            # record validation loss\n",
    "            valid_losses.append(valloss.item())\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "              \n",
    "        scheduler.step(valloss)\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    " \n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model,test_loader,i,mode):\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    for n,(x, y) in enumerate(test_loader):\n",
    "        if n==i:\n",
    "            if mode==\"inference\":\n",
    "                y_pred=model(x.float(),1,gpu=False).detach().numpy().squeeze()\n",
    "            if mode==\"mpc_test\":\n",
    "                y_pred=model.mpc_test(x.float(),1,gpu=False).detach().numpy().squeeze()\n",
    "                \n",
    "            y_name=[\"Water\",\"IPAC\"]\n",
    "            y_predicted=pd.DataFrame(np.array(y_pred),columns=[y_name])\n",
    "            Y_testing=pd.DataFrame(y.detach().numpy().squeeze(),columns=[y_name])\n",
    "    for i , element in enumerate(y_name):\n",
    "        from sklearn.metrics import r2_score\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        plt.subplot(2,len(y_name)/2,i+1)\n",
    "        plt.title(element)\n",
    "        plt.scatter( y_predicted[[element]].index,y_predicted[[element]], color='r',s=2)\n",
    "        plt.scatter( Y_testing[[element]].index,Y_testing[[element]], color='g',s=2)\n",
    "        plt.legend(['predicted','real'],fontsize=15)\n",
    "        print(\"{} R2:\".format(element),r2_score(Y_testing[[element]],y_predicted[[element]]))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training data\n",
    "training_data_describe=training_data_describe('IPAC_rawdata_0610.csv')\n",
    "\n",
    "y_num=2\n",
    "featureNum=5\n",
    "past=10\n",
    "WindowsSize=30     #past +predict horizon= windowsize\n",
    "\n",
    "training_set=pd.read_csv('IPAC_rawdata_0610.csv')\n",
    "training_set_norm=data_norm(training_set)\n",
    "training_set_norm[\"IPAC_+1\"]=training_set_norm[\"IPAC\"].shift(-1)\n",
    "training_set_norm[\"WATER_+1\"]=training_set_norm[\"WATER\"].shift(-1)\n",
    "training_set_norm=training_set_norm.dropna()\n",
    "X_train, Y_train,X_val, Y_val=window_p(training_set_norm,\"Train\")\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"Y_train: \",Y_train.shape)\n",
    "\n",
    "torch_dataset_train = PrepareData(X_train,Y_train)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset_train,      # torch TensorDataset format\n",
    "    batch_size=50,                    # mini batch size\n",
    "    shuffle=True,                     # shuffle the data\n",
    "    num_workers=0,                    # 多線程讀數據\n",
    "    drop_last=True \n",
    "    )\n",
    "\n",
    "torch_dataset_val = PrepareData(X_val, Y_val)\n",
    "valid_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset_val,      \n",
    "    batch_size=50,                  \n",
    "    shuffle=True,                   \n",
    "    num_workers=0,                  \n",
    "    drop_last=True                  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model and training \n",
    "model = softsensor(5,64,32,2,gpu=True)\n",
    "model.to('cuda:0')\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',verbose=True,patience=3)\n",
    "\n",
    "model, train_loss, valid_loss=train_model(model,  batch_size=50, patience=5, n_epochs=100,gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 0.03) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot_64_32.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model validation\n",
    "testing_set=pd.read_csv('IPAC_valdata_0610.csv')\n",
    "testing_set_norm=data_norm(testing_set)\n",
    "testing_set_norm[\"IPAC_+1\"]=testing_set_norm[\"IPAC\"].shift(-1)\n",
    "testing_set_norm[\"WATER_+1\"]=testing_set_norm[\"WATER\"].shift(-1)\n",
    "testing_set_norm=testing_set_norm.dropna()\n",
    "X_test, Y_test=window_p(testing_set_norm,\"Test\")\n",
    "torch_dataset_test = PrepareData(X_test,Y_test)\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset_test,      # torch TensorDataset format\n",
    "    batch_size=1,      # mini batch size              \n",
    "    num_workers=0 # 多线程来读数据\n",
    ")\n",
    "for i in range(X_test.shape[0]):\n",
    "    if i%50==0:\n",
    "        print('-------------------------- {} -------------------------------------'.format(i))\n",
    "        y_pred=model_test(model,test_loader,i,mode=\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPC test\n",
    "\n",
    "#import model\n",
    "#model = softsensor(5,64,32,2,gpu=False)\n",
    "#model.load_state_dict(torch.load(\"lstmcell_64_32_win10_0610.pt\"))\n",
    "#print(model)\n",
    "\n",
    "testing_set=pd.read_csv('IPAC_valdata_0610.csv')\n",
    "testing_set_norm=data_norm(testing_set)\n",
    "testing_set_norm[\"IPAC_+1\"]=testing_set_norm[\"IPAC\"].shift(-1)\n",
    "testing_set_norm[\"WATER_+1\"]=testing_set_norm[\"WATER\"].shift(-1)\n",
    "testing_set_norm=testing_set_norm.dropna()\n",
    "X_test, Y_test=window_p(testing_set_norm,\"Test\")\n",
    "torch_dataset_test = PrepareData(X_test,Y_test)\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset_test,      # torch TensorDataset format\n",
    "    batch_size=1,      # mini batch size              \n",
    "    num_workers=0 # 多线程来读数据\n",
    ")\n",
    "for i in range(X_test.shape[0]):\n",
    "    if i%50==0:\n",
    "        print('-------------------------- {} -------------------------------------'.format(i))\n",
    "        y_pred=model_mpc_test(model,test_loader,i,mode=\"mpc_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
